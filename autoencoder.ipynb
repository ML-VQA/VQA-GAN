{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imsave\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "#from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import copy\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "savepath = '../data/'\n",
    "images = glob.glob(path+'sources/nparrs_384/*.npy')\n",
    "totalImages = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "36\n",
      "39\n",
      "40\n",
      "41\n",
      "44\n",
      "47\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "tile_sizes = np.loadtxt(path+'sources/complex_scenes/tile_sizes.txt', dtype='int')\n",
    "images_sampled = {}\n",
    "for tile in tile_sizes:\n",
    "    if tile[2] > 200000:\n",
    "        print(tile[0])\n",
    "        #for i in range(30):\n",
    "        #    images_sampled.setdefault(tile[0]*30+i, []).append(tile[1])\n",
    "        #    print(tile[0]*30+i)\n",
    "        #    os.system('mv ../data/sources/nparrs_384/frame'+str(tile[0]*30+i)+'.npy ../data/sources/new_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(batch_size):\n",
    "    while True:\n",
    "        #index_list = random.sample(range(1, totalImages), batch_size)\n",
    "        index_list = random.sample(images_sampled.keys(), batch_size)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            frame = path+'sources/nparrs_384/frame'+str(i)+'.npy' #images[i]\n",
    "            frame = np.load(frame)\n",
    "            #tile_index = np.random.randint(0, 199)\n",
    "            tile_index = random.choice(images_sampled[i])\n",
    "            #print(i, tile_index, frame.shape, images_sampled[i])\n",
    "            alldata_x.append(tile_index*totalImages+i)\n",
    "            alldata_y.append(frame[tile_index])\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        #alldata_y = alldata_y/255.0\n",
    "        alldata_y = (alldata_y.astype(np.float32) - 127.5) / 127.5\n",
    "        yield alldata_y, alldata_y\n",
    "#x = myGenerator()\n",
    "#xtrain, ytrain = next(x)\n",
    "#print('xtrain shape:',xtrain.shape)\n",
    "#print('ytrain shape:',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 384\n",
    "        self.img_cols = 384\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "        self.latent_dim = 300\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['mse'],\n",
    "            optimizer=self.optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        #print(self.discriminator.summary())\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        print(self.generator.summary())\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim, ))\n",
    "        img = self.generator(noise)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(noise, valid)\n",
    "        self.combined.compile(loss=['mse'],\n",
    "            optimizer=self.optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(64 * 48 * 48, input_dim=300))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Reshape((48, 48, 64)))\n",
    "\n",
    "        model.add(Conv2D(512, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Conv2D(512, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "    \n",
    "        model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img   = model(noise)\n",
    "        return model\n",
    "    \n",
    "    def build_autoencoder(self):\n",
    "        self.generator.compile(loss=['mse'], optimizer=self.optimizer)\n",
    "    \n",
    "    def train_generator_autoencoder(self, epochs, batch_size=128, sample_interval=10):\n",
    "        for epoch in range(epochs):\n",
    "            X_train, y_train = next(myGenerator(batch_size))\n",
    "            g_loss = self.generator.train_on_batch(X_train, X_train)\n",
    "            print (\"Epoch \", epoch, \" G loss \", g_loss)\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "                self.generator.save_weights(savepath+'weights/generator_weights_'+str(epoch)+'.h5')\n",
    "            \n",
    "    def build_discriminator(self):\n",
    "        img   = Input(shape=(384, 384, 3))\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (3, 3), input_shape=(384, 384, 3)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64,  (3, 3),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Conv2D(64, (6, 6),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Conv2D(64, (3, 3),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, (3, 3),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(32))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        output    = model(img)\n",
    "        model3    = Model(img, output)\n",
    "        return model3\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "        random.seed(10)\n",
    "        \n",
    "        # Load the dataset\n",
    "        for epoch in range(epochs):\n",
    "            X_train, y_train = next(myGenerator(batch_size))\n",
    "            \n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            valid = np.ones((batch_size, 1))\n",
    "            fake  = np.zeros((batch_size, 1))\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            \n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(X_train, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "                self.generator.save_weights(savepath+'weights/generator_weights_'+str(epoch)+'.h5')\n",
    "                self.discriminator.save_weights(savepath+'weights/discriminator_weights_'+str(epoch)+'.h5')\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c             = 1, 10\n",
    "        noise            = np.random.normal(0, 1, (5, self.latent_dim))\n",
    "        gen_imgs         = self.generator.predict(noise)\n",
    "        \n",
    "        # Rescale images 0 - 1\n",
    "        temp     = (0.5 * gen_imgs + 0.5)*255\n",
    "        gen_imgs = temp.astype(int)\n",
    "        \n",
    "        combined = np.array([gen_imgs[0], gen_imgs[1], gen_imgs[2], gen_imgs[3], gen_imgs[4]])\n",
    "        combined = np.hstack(combined.reshape(5, 384,384, 3))\n",
    "        imsave(savepath+\"images/\"+str(epoch)+\".png\", combined)\n",
    "        \n",
    "#         combined = np.array([Y_train[0], Y_train[1], Y_train[2], Y_train[3], Y_train[4]])\n",
    "#         combined = np.hstack(combined.reshape(5, 384,384, 3))\n",
    "#         imsave(savepath+\"images/\"+str(epoch)+\"_real.png\", combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.223306, acc.: 16.67%] [G loss: 1.396989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:197: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 2.024251, acc.: 0.00%] [G loss: 0.349265]\n",
      "2 [D loss: 0.808640, acc.: 16.67%] [G loss: 1.684965]\n",
      "3 [D loss: 1.223683, acc.: 8.33%] [G loss: 0.823112]\n",
      "4 [D loss: 0.283793, acc.: 58.33%] [G loss: 1.411553]\n",
      "5 [D loss: 1.123776, acc.: 8.33%] [G loss: 0.859192]\n",
      "6 [D loss: 0.651682, acc.: 58.33%] [G loss: 0.996691]\n",
      "7 [D loss: 0.383138, acc.: 41.67%] [G loss: 0.524241]\n",
      "8 [D loss: 0.560757, acc.: 25.00%] [G loss: 0.380499]\n",
      "9 [D loss: 0.751784, acc.: 25.00%] [G loss: 0.486691]\n",
      "10 [D loss: 0.658768, acc.: 33.33%] [G loss: 0.948579]\n",
      "11 [D loss: 0.413986, acc.: 33.33%] [G loss: 0.447227]\n",
      "12 [D loss: 0.350984, acc.: 50.00%] [G loss: 1.068667]\n",
      "13 [D loss: 0.488844, acc.: 33.33%] [G loss: 0.850647]\n",
      "14 [D loss: 0.663066, acc.: 16.67%] [G loss: 0.338115]\n",
      "15 [D loss: 0.526799, acc.: 33.33%] [G loss: 0.472555]\n",
      "16 [D loss: 0.554724, acc.: 16.67%] [G loss: 0.424880]\n",
      "17 [D loss: 0.348369, acc.: 58.33%] [G loss: 0.684113]\n",
      "18 [D loss: 0.397686, acc.: 41.67%] [G loss: 0.542699]\n",
      "19 [D loss: 0.530719, acc.: 33.33%] [G loss: 0.882889]\n",
      "20 [D loss: 0.452525, acc.: 50.00%] [G loss: 0.667495]\n",
      "21 [D loss: 0.434063, acc.: 16.67%] [G loss: 0.444977]\n",
      "22 [D loss: 0.221306, acc.: 58.33%] [G loss: 0.720863]\n",
      "23 [D loss: 0.370232, acc.: 50.00%] [G loss: 0.370025]\n",
      "24 [D loss: 0.255155, acc.: 50.00%] [G loss: 0.641559]\n",
      "25 [D loss: 0.365640, acc.: 50.00%] [G loss: 1.010712]\n",
      "26 [D loss: 0.487048, acc.: 58.33%] [G loss: 0.404673]\n",
      "27 [D loss: 0.322375, acc.: 50.00%] [G loss: 0.679685]\n",
      "28 [D loss: 0.526112, acc.: 33.33%] [G loss: 0.612754]\n",
      "29 [D loss: 0.541031, acc.: 33.33%] [G loss: 0.380465]\n",
      "30 [D loss: 0.487834, acc.: 41.67%] [G loss: 0.760544]\n",
      "31 [D loss: 0.122116, acc.: 75.00%] [G loss: 1.393582]\n",
      "32 [D loss: 0.813909, acc.: 16.67%] [G loss: 0.193920]\n",
      "33 [D loss: 0.477226, acc.: 33.33%] [G loss: 0.573477]\n",
      "34 [D loss: 0.186818, acc.: 83.33%] [G loss: 1.065341]\n",
      "35 [D loss: 0.346625, acc.: 50.00%] [G loss: 0.224492]\n",
      "36 [D loss: 0.158559, acc.: 75.00%] [G loss: 0.590394]\n",
      "37 [D loss: 0.438720, acc.: 33.33%] [G loss: 0.725898]\n",
      "38 [D loss: 0.166399, acc.: 66.67%] [G loss: 0.720162]\n",
      "39 [D loss: 0.556100, acc.: 41.67%] [G loss: 0.514416]\n",
      "40 [D loss: 0.421845, acc.: 50.00%] [G loss: 0.887784]\n",
      "41 [D loss: 0.288581, acc.: 50.00%] [G loss: 0.551713]\n",
      "42 [D loss: 0.486445, acc.: 25.00%] [G loss: 0.457830]\n",
      "43 [D loss: 0.165277, acc.: 66.67%] [G loss: 0.390766]\n",
      "44 [D loss: 0.176713, acc.: 66.67%] [G loss: 0.846739]\n",
      "45 [D loss: 0.520410, acc.: 33.33%] [G loss: 0.483134]\n",
      "46 [D loss: 0.524308, acc.: 33.33%] [G loss: 0.523627]\n",
      "47 [D loss: 0.239056, acc.: 50.00%] [G loss: 0.757993]\n",
      "48 [D loss: 0.358818, acc.: 33.33%] [G loss: 0.652937]\n",
      "49 [D loss: 0.236829, acc.: 66.67%] [G loss: 0.925765]\n",
      "50 [D loss: 0.407943, acc.: 41.67%] [G loss: 0.166994]\n",
      "51 [D loss: 0.369741, acc.: 41.67%] [G loss: 0.484681]\n",
      "52 [D loss: 0.202754, acc.: 75.00%] [G loss: 0.624616]\n",
      "53 [D loss: 0.143828, acc.: 83.33%] [G loss: 0.718007]\n",
      "54 [D loss: 0.378046, acc.: 58.33%] [G loss: 0.341401]\n",
      "55 [D loss: 0.403464, acc.: 33.33%] [G loss: 0.504534]\n",
      "56 [D loss: 0.365257, acc.: 41.67%] [G loss: 0.367390]\n",
      "57 [D loss: 0.423865, acc.: 58.33%] [G loss: 0.989384]\n",
      "58 [D loss: 0.375082, acc.: 41.67%] [G loss: 0.477566]\n",
      "59 [D loss: 0.246990, acc.: 58.33%] [G loss: 1.562807]\n",
      "60 [D loss: 0.497025, acc.: 33.33%] [G loss: 0.653967]\n",
      "61 [D loss: 0.317688, acc.: 41.67%] [G loss: 0.626395]\n",
      "62 [D loss: 0.193688, acc.: 58.33%] [G loss: 0.614676]\n",
      "63 [D loss: 0.380412, acc.: 50.00%] [G loss: 0.982938]\n",
      "64 [D loss: 0.189740, acc.: 83.33%] [G loss: 0.826985]\n",
      "65 [D loss: 0.552990, acc.: 25.00%] [G loss: 0.307089]\n",
      "66 [D loss: 0.156548, acc.: 83.33%] [G loss: 0.712388]\n",
      "67 [D loss: 0.237989, acc.: 50.00%] [G loss: 0.491976]\n",
      "68 [D loss: 0.296324, acc.: 75.00%] [G loss: 0.654746]\n",
      "69 [D loss: 0.187266, acc.: 66.67%] [G loss: 0.592127]\n",
      "70 [D loss: 0.202156, acc.: 66.67%] [G loss: 0.686644]\n",
      "71 [D loss: 0.177215, acc.: 75.00%] [G loss: 0.725414]\n",
      "72 [D loss: 0.096914, acc.: 91.67%] [G loss: 0.992450]\n",
      "73 [D loss: 0.096680, acc.: 91.67%] [G loss: 0.686993]\n",
      "74 [D loss: 0.112593, acc.: 91.67%] [G loss: 0.555532]\n",
      "75 [D loss: 0.097689, acc.: 91.67%] [G loss: 0.585935]\n",
      "76 [D loss: 0.196970, acc.: 83.33%] [G loss: 0.613360]\n",
      "77 [D loss: 0.110900, acc.: 83.33%] [G loss: 0.657874]\n",
      "78 [D loss: 0.153309, acc.: 75.00%] [G loss: 0.852921]\n",
      "79 [D loss: 0.148139, acc.: 83.33%] [G loss: 1.049483]\n",
      "80 [D loss: 0.080071, acc.: 91.67%] [G loss: 1.315044]\n",
      "81 [D loss: 0.133748, acc.: 83.33%] [G loss: 0.589813]\n",
      "82 [D loss: 0.098723, acc.: 91.67%] [G loss: 0.768783]\n",
      "83 [D loss: 0.125475, acc.: 91.67%] [G loss: 1.021306]\n",
      "84 [D loss: 0.153639, acc.: 83.33%] [G loss: 0.769371]\n",
      "85 [D loss: 0.203014, acc.: 66.67%] [G loss: 1.088047]\n",
      "86 [D loss: 0.067354, acc.: 100.00%] [G loss: 1.184722]\n",
      "87 [D loss: 0.113242, acc.: 83.33%] [G loss: 0.602484]\n",
      "88 [D loss: 0.099610, acc.: 83.33%] [G loss: 1.166730]\n",
      "89 [D loss: 0.190995, acc.: 66.67%] [G loss: 0.705983]\n",
      "90 [D loss: 0.068603, acc.: 100.00%] [G loss: 0.980554]\n",
      "91 [D loss: 0.081546, acc.: 91.67%] [G loss: 1.144259]\n",
      "92 [D loss: 0.434174, acc.: 50.00%] [G loss: 0.726753]\n",
      "93 [D loss: 0.063344, acc.: 100.00%] [G loss: 0.878600]\n",
      "94 [D loss: 0.418752, acc.: 50.00%] [G loss: 0.749562]\n",
      "95 [D loss: 0.246851, acc.: 50.00%] [G loss: 0.788997]\n",
      "96 [D loss: 0.116081, acc.: 83.33%] [G loss: 0.948261]\n",
      "97 [D loss: 0.205054, acc.: 75.00%] [G loss: 0.853875]\n",
      "98 [D loss: 0.117491, acc.: 83.33%] [G loss: 1.092822]\n",
      "99 [D loss: 0.174162, acc.: 83.33%] [G loss: 0.722937]\n",
      "100 [D loss: 0.101038, acc.: 83.33%] [G loss: 0.648753]\n",
      "101 [D loss: 0.167209, acc.: 83.33%] [G loss: 0.547911]\n",
      "102 [D loss: 0.229102, acc.: 75.00%] [G loss: 1.028824]\n",
      "103 [D loss: 0.423286, acc.: 50.00%] [G loss: 0.695008]\n",
      "104 [D loss: 0.176803, acc.: 75.00%] [G loss: 0.610762]\n",
      "105 [D loss: 0.116169, acc.: 83.33%] [G loss: 1.122529]\n",
      "106 [D loss: 0.231100, acc.: 66.67%] [G loss: 0.892095]\n",
      "107 [D loss: 0.093575, acc.: 91.67%] [G loss: 0.595056]\n",
      "108 [D loss: 0.136284, acc.: 75.00%] [G loss: 1.014206]\n",
      "109 [D loss: 0.189346, acc.: 66.67%] [G loss: 0.889015]\n",
      "110 [D loss: 0.058335, acc.: 91.67%] [G loss: 0.571528]\n",
      "111 [D loss: 0.152196, acc.: 83.33%] [G loss: 0.758573]\n",
      "112 [D loss: 0.048751, acc.: 100.00%] [G loss: 0.909336]\n",
      "113 [D loss: 0.083725, acc.: 91.67%] [G loss: 1.084901]\n",
      "114 [D loss: 0.054530, acc.: 91.67%] [G loss: 0.812052]\n",
      "115 [D loss: 0.148469, acc.: 75.00%] [G loss: 1.149498]\n",
      "116 [D loss: 0.140477, acc.: 83.33%] [G loss: 0.723410]\n",
      "117 [D loss: 0.090379, acc.: 91.67%] [G loss: 0.810574]\n",
      "118 [D loss: 0.240950, acc.: 58.33%] [G loss: 0.568523]\n",
      "119 [D loss: 0.109280, acc.: 91.67%] [G loss: 0.890321]\n",
      "120 [D loss: 0.198530, acc.: 75.00%] [G loss: 0.878338]\n",
      "121 [D loss: 0.130429, acc.: 75.00%] [G loss: 0.807033]\n",
      "122 [D loss: 0.167160, acc.: 66.67%] [G loss: 0.864271]\n",
      "123 [D loss: 0.178249, acc.: 58.33%] [G loss: 0.418085]\n",
      "124 [D loss: 0.089342, acc.: 83.33%] [G loss: 1.219621]\n",
      "125 [D loss: 0.188114, acc.: 75.00%] [G loss: 0.771183]\n",
      "126 [D loss: 0.810830, acc.: 33.33%] [G loss: 0.372557]\n",
      "127 [D loss: 0.290756, acc.: 66.67%] [G loss: 0.506377]\n",
      "128 [D loss: 0.068627, acc.: 91.67%] [G loss: 0.986252]\n",
      "129 [D loss: 0.302888, acc.: 58.33%] [G loss: 0.688137]\n",
      "130 [D loss: 0.260197, acc.: 66.67%] [G loss: 0.900748]\n",
      "131 [D loss: 0.204912, acc.: 66.67%] [G loss: 0.760992]\n",
      "132 [D loss: 0.136297, acc.: 75.00%] [G loss: 1.108439]\n",
      "133 [D loss: 0.110112, acc.: 91.67%] [G loss: 1.013372]\n",
      "134 [D loss: 0.188269, acc.: 66.67%] [G loss: 0.875501]\n",
      "135 [D loss: 0.136529, acc.: 83.33%] [G loss: 0.809245]\n",
      "136 [D loss: 0.214043, acc.: 83.33%] [G loss: 0.772911]\n",
      "137 [D loss: 0.050443, acc.: 100.00%] [G loss: 1.223362]\n",
      "138 [D loss: 0.192293, acc.: 66.67%] [G loss: 0.629795]\n",
      "139 [D loss: 0.076142, acc.: 91.67%] [G loss: 1.145476]\n",
      "140 [D loss: 0.115601, acc.: 83.33%] [G loss: 0.900140]\n",
      "141 [D loss: 0.291952, acc.: 58.33%] [G loss: 0.686467]\n",
      "142 [D loss: 0.217544, acc.: 66.67%] [G loss: 0.516060]\n",
      "143 [D loss: 0.197345, acc.: 75.00%] [G loss: 0.989568]\n",
      "144 [D loss: 0.209446, acc.: 66.67%] [G loss: 0.709597]\n",
      "145 [D loss: 0.300748, acc.: 75.00%] [G loss: 0.611691]\n",
      "146 [D loss: 0.299541, acc.: 66.67%] [G loss: 0.739620]\n",
      "147 [D loss: 0.044351, acc.: 100.00%] [G loss: 0.997914]\n",
      "148 [D loss: 0.171794, acc.: 66.67%] [G loss: 0.892825]\n",
      "149 [D loss: 0.114354, acc.: 83.33%] [G loss: 0.961004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 [D loss: 0.083728, acc.: 91.67%] [G loss: 0.925153]\n",
      "151 [D loss: 0.151300, acc.: 75.00%] [G loss: 0.784853]\n",
      "152 [D loss: 0.093862, acc.: 91.67%] [G loss: 1.182332]\n",
      "153 [D loss: 0.112701, acc.: 91.67%] [G loss: 0.770609]\n",
      "154 [D loss: 0.184744, acc.: 83.33%] [G loss: 0.828339]\n",
      "155 [D loss: 0.131209, acc.: 83.33%] [G loss: 0.702797]\n",
      "156 [D loss: 0.222715, acc.: 83.33%] [G loss: 1.042773]\n",
      "157 [D loss: 0.125254, acc.: 83.33%] [G loss: 0.968901]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0f89d15f2e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#cgan.build_discriminator()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#cgan.build_generator()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#cgan.build_autoencoder()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#cgan.train_generator_autoencoder(100000, 8, 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f128ba4bb624>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fa7f03093aed>\u001b[0m in \u001b[0;36mmyGenerator\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'sources/nparrs_384/frame'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m \u001b[0;31m#images[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;31m#tile_index = np.random.randint(0, 199)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtile_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_sampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 433\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cgan = CGAN()\n",
    "#cgan.build_discriminator()\n",
    "#cgan.build_generator()\n",
    "cgan.train(100000, 6, 100)\n",
    "#cgan.build_autoencoder()\n",
    "#cgan.train_generator_autoencoder(100000, 8, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(100):\n",
    "    x = myGenerator(1)\n",
    "    xtest, ytest = next(x)\n",
    "    #print('xtrain shape:',xtest.shape)\n",
    "    #print('ytrain shape:',ytest.shape)\n",
    "    pred = cgan.generator.predict(xtest)\n",
    "    pred = pred*127.5 + 127.5\n",
    "    pred = pred.astype(int)\n",
    "    print(pred.dtype)\n",
    "    plt.imshow(pred[0])\n",
    "    plt.show()\n",
    "    ytest = ytest*127.5+127.5\n",
    "    ytest = ytest.astype(int)\n",
    "    plt.imshow(ytest[0])\n",
    "    plt.show()\n",
    "    #break\n",
    "    #time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
