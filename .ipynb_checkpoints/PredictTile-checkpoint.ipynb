{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imsave\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "#from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/nparrs/'\n",
    "savepath = '../data/'\n",
    "images = glob.glob(path+'*.npy')\n",
    "totalImages = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(batch_size):\n",
    "    while True:\n",
    "        index_list = random.sample(range(1, totalImages), batch_size)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            frame = images[i]\n",
    "            frame = np.load(frame)\n",
    "            tile_index = np.random.randint(0, 199)\n",
    "            #print(i, tile_index, frame.shape)\n",
    "            alldata_x.append(tile_index*totalImages+i)\n",
    "            alldata_y.append(frame[tile_index])\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        #alldata_x = np.rollaxis(alldata_x, 1, 5)  \n",
    "        #alldata_x = alldata_x.reshape((32, 30, 240, 480, 3))\n",
    "        #alldata_x = np.swapaxes(alldata_x, 1, 4)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        alldata_y = (alldata_y.astype(np.float32) - 127.5) / 127.5\n",
    "        yield alldata_x, alldata_y\n",
    "#x = myGenerator()\n",
    "#xtrain, ytrain = next(x)\n",
    "#print('xtrain shape:',xtrain.shape)\n",
    "#print('ytrain shape:',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 192\n",
    "        self.img_cols = 192\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 360000\n",
    "        self.latent_dim  = 200\n",
    "        self.embedding_layer = Embedding(self.num_classes, self.latent_dim)\n",
    "        \n",
    "        self.test_tiles = np.array([np.random.randint(0, 1800*200, 10)])\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['mse'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(1,))\n",
    "        #label = Input(shape=(1,))\n",
    "        img = self.generator(noise)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, noise])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(noise, valid)\n",
    "        self.combined.compile(loss=['mse'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(192 * 192 * 3, activation='relu', input_dim=self.latent_dim))\n",
    "        model.add(Reshape((192, 192, 3)))\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        label           = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(self.embedding_layer(label))\n",
    "        img             = model(label_embedding)\n",
    "\n",
    "        model2 =  Model(label, img)\n",
    "        print(model2.summary())\n",
    "        return model2\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        img   = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(self.embedding_layer(label))\n",
    "        \n",
    "        label_dense = Dense(100)(label_embedding)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (3, 3), input_shape=(192, 192, 3)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64,  (3, 3),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, (6, 6),  strides=(2, 2)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, (3, 3),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, (3, 3)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(128, (3, 3),  strides=(2, 2)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        #model.add(Dense(512))\n",
    "        #model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        dense100    = model(img)\n",
    "        conditioned = multiply([dense100, label_dense])\n",
    "        #dense64     = Dense(128)(conditioned)\n",
    "        #dense64l    = LeakyReLU(alpha=0.2)(dense64)\n",
    "        dense32     = Dense(32)(conditioned)\n",
    "        dense32l    = LeakyReLU(alpha=0.2)(dense32)\n",
    "        \n",
    "        #For ls gan\n",
    "        validity = Dense(1)(dense32l)\n",
    "        #validity = Dense(1, activation='sigmoid')(dense32l)\n",
    "        \n",
    "        model3 = Model([img, label], validity) \n",
    "        print(model3.summary())\n",
    "        return model3\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "        random.seed(10)\n",
    "        \n",
    "        # Load the dataset\n",
    "        for epoch in range(epochs):\n",
    "            X_train, y_train = next(myGenerator(batch_size))\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            valid = np.ones((batch_size, 1))\n",
    "            fake  = np.zeros((batch_size, 1))\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            #idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            noise, imgs = X_train, y_train\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            # noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, noise], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, noise], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            #sampled_labels = np.random.randint(0, 7, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                #self.sample_images(epoch)\n",
    "                self.generator.save_weights(savepath+'weights/generator_weights_'+str(epoch)+'.h5')\n",
    "                self.discriminator.save_weights(savepath+'weights/discriminator_weights_'+str(epoch)+'.h5')\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 1, 7\n",
    "        noise          = self.test_tiles\n",
    "\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        temp = (0.5 * gen_imgs + 0.5)*255\n",
    "        gen_imgs = temp.astype(int)\n",
    "        #print(gen_imgs[0].shape)\n",
    "        combined = np.array([gen_imgs[0], gen_imgs[1], gen_imgs[2], gen_imgs[3], gen_imgs[4], gen_imgs[5], gen_imgs[6]])\n",
    "        #print(combined.shape)\n",
    "        combined = np.hstack(combined.reshape(7,192,192, 3))\n",
    "        imsave(savepath+\"images/\"+str(epoch)+\".png\", combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 200)       72000000    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 192, 192, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 100)          1520228     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          20100       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100)          0           sequential_1[1][0]               \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           3232        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          leaky_re_lu_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 73,543,593\n",
      "Trainable params: 73,542,697\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1, 200)            72000000  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 192, 192, 3)       22608515  \n",
      "=================================================================\n",
      "Total params: 94,608,515\n",
      "Trainable params: 94,607,619\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cgan = CGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.494168, acc.: 50.00%] [G loss: 0.930064]\n",
      "1 [D loss: 0.485253, acc.: 50.00%] [G loss: 0.945789]\n",
      "2 [D loss: 0.481890, acc.: 50.00%] [G loss: 0.931754]\n",
      "3 [D loss: 0.496469, acc.: 50.00%] [G loss: 0.954482]\n",
      "4 [D loss: 0.503397, acc.: 50.00%] [G loss: 0.937775]\n",
      "5 [D loss: 0.455051, acc.: 50.00%] [G loss: 0.866678]\n",
      "6 [D loss: 0.482300, acc.: 50.00%] [G loss: 0.831939]\n",
      "7 [D loss: 0.469317, acc.: 50.00%] [G loss: 0.831425]\n",
      "8 [D loss: 0.439421, acc.: 50.00%] [G loss: 0.847092]\n",
      "9 [D loss: 0.438705, acc.: 50.00%] [G loss: 0.736288]\n"
     ]
    }
   ],
   "source": [
    "cgan.train(1000000, batch_size=10, sample_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
