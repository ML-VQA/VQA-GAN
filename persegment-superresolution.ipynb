{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imsave\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "#from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import copy\n",
    "import cv2\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "savepath = '../data/'\n",
    "#images = glob.glob(path+'new_data/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "tile_sizes = np.loadtxt(path+'tile_sizes.txt', dtype='int')\n",
    "tile_sizes = tile_sizes[350:400]\n",
    "images_sampled = {}\n",
    "for tile in tile_sizes:\n",
    "    for i in range(1, 201):\n",
    "        images_sampled.setdefault(tile[0]*30+i, []).append(tile[1])\n",
    "print(len(images_sampled.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(batch_size):\n",
    "    s = 640\n",
    "    while True:\n",
    "        index_list = random.sample(images_sampled.keys(), batch_size)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            frame = path+'sources/nparrs_384/frame'+str(i)+'.npy'\n",
    "            frame = np.load(frame)\n",
    "            tile_index = random.choice(images_sampled[i])\n",
    "            \n",
    "            tmp = imresize(frame[tile_index], (s, 480))\n",
    "            temp  = imresize(frame[tile_index], (48, 48))\n",
    "            temp  = imresize(temp, (s, 480))\n",
    "            \n",
    "            alldata_x.append(temp)\n",
    "            #alldata_y.append(frame[tile_index])\n",
    "            alldata_y.append(tmp)\n",
    "        \n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        \n",
    "        alldata_y = (alldata_y.astype(np.float32) - 127.5) / 127.5\n",
    "        alldata_x = alldata_x.astype(np.float32)/255.0\n",
    "        \n",
    "        yield alldata_x, alldata_y\n",
    "\n",
    "#x = myGenerator(10)\n",
    "#xtrain, ytrain = next(x)\n",
    "#print('xtrain shape:',xtrain.shape)\n",
    "#print('ytrain shape:',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        s = 640\n",
    "        self.img_rows = s\n",
    "        self.img_cols = 480\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        #self.discriminator = self.build_discriminator()\n",
    "        #self.discriminator.compile(loss=['mse'],\n",
    "        #    optimizer=optimizer,\n",
    "        #    metrics=['accuracy'])\n",
    "        \n",
    "        #print(self.discriminator.summary())\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        print(self.generator.summary())\n",
    "        \n",
    "        noise = Input(shape=(self.img_rows, self.img_cols, 3))\n",
    "        img = self.generator(noise)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        #self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        #valid = self.discriminator(img)\n",
    "        \n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        #self.combined = Model(noise, [img, valid])\n",
    "        #self.combined.compile(loss=['mse', 'mse'],\n",
    "        #    loss_weights=[0.9, 0.1],\n",
    "        #    optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        filter_size = 8\n",
    "        input_size = (self.img_rows, self.img_cols,3)\n",
    "        inputs = Input(input_size)\n",
    "\n",
    "        conv1 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        conv1 = LeakyReLU()(conv1)\n",
    "        conv1 = BatchNormalization(momentum=0.8)(conv1)\n",
    "\n",
    "        conv2 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        conv2 = LeakyReLU()(conv2)\n",
    "        conv2 = BatchNormalization(momentum=0.8)(conv2)\n",
    "\n",
    "        conv3 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        conv3 = LeakyReLU()(conv3)\n",
    "        conv3 = BatchNormalization(momentum=0.8)(conv3)\n",
    "\n",
    "        concat1 = add([conv1, conv3])\n",
    "\n",
    "        conv4 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(concat1)\n",
    "        conv4 = LeakyReLU()(conv4)\n",
    "        conv4 = BatchNormalization(momentum=0.8)(conv4)\n",
    "\n",
    "        conv5 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        conv5 = LeakyReLU()(conv5)\n",
    "        conv5 = BatchNormalization(momentum=0.8)(conv5)\n",
    "\n",
    "        concat2 = add([conv5, concat1])\n",
    "\n",
    "        conv6 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(concat2)\n",
    "        conv6 = LeakyReLU()(conv6)\n",
    "        conv6 = BatchNormalization(momentum=0.8)(conv6)\n",
    "\n",
    "        conv7 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "        conv7 = LeakyReLU()(conv7)\n",
    "        conv7 = BatchNormalization(momentum=0.8)(conv7)\n",
    "\n",
    "        concat3 = add([conv7, concat2])\n",
    "\n",
    "        conv8 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(concat3)\n",
    "        conv8 = LeakyReLU()(conv8)\n",
    "        conv8 = BatchNormalization(momentum=0.8)(conv8)\n",
    "\n",
    "        conv9 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "        conv9 = LeakyReLU()(conv9)\n",
    "        conv9 = BatchNormalization(momentum=0.8)(conv9)\n",
    "        \n",
    "\n",
    "        conv10 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = LeakyReLU()(conv10)\n",
    "        conv10 = BatchNormalization(momentum=0.8)(conv10)\n",
    "\n",
    "        concat4 = add([conv10, conv1])\n",
    "        \n",
    "        conv11 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(concat4)\n",
    "        conv11 = LeakyReLU()(conv11)\n",
    "        conv11 = BatchNormalization(momentum=0.8)(conv11)\n",
    "        \n",
    "        conv12 = Conv2D(filter_size, 3, padding = 'same', kernel_initializer = 'he_normal')(conv11)\n",
    "        conv12 = PReLU()(conv12)\n",
    "        conv12 = BatchNormalization(momentum=0.8)(conv12)\n",
    "\n",
    "\n",
    "        out = Conv2D(3, 3, padding = 'same', kernel_initializer = 'he_normal')(conv12)\n",
    "        out = LeakyReLU()(out)\n",
    "        out = BatchNormalization(momentum=0.8)(out)\n",
    "\n",
    "\n",
    "        model = Model(input = inputs, output = out)\n",
    "        return model\n",
    "    \n",
    "    def build_autoencoder(self):\n",
    "        self.generator.compile(loss=['mse'],optimizer=self.optimizer)\n",
    "    \n",
    "    def train_generator_autoencoder(self, epochs, batch_size=128, sample_interval=10):\n",
    "        for epoch in range(epochs):\n",
    "            X_train, y_train = next(myGenerator(batch_size))\n",
    "            g_loss = self.generator.train_on_batch(X_train, y_train)\n",
    "            print (\"Epoch \", epoch, \" G loss \", g_loss)\n",
    "            #if epoch % sample_interval == 0:\n",
    "                #self.sample_images(epoch)\n",
    "                #self.generator.save_weights(savepath+'Per-segment-models/8/generator_weights_'+str(epoch)+'.h5')\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c             = 1, 10\n",
    "        X_train, y_train = next(myGenerator(10))\n",
    "        gen_imgs         = self.generator.predict(X_train)\n",
    "        \n",
    "        # Rescale images 0 - 1\n",
    "        temp     = (0.5 * gen_imgs + 0.5)*255\n",
    "        gen_imgs = temp.astype(int)\n",
    "        y_train = (0.5 * y_train + 0.5)*255\n",
    "        y_train = y_train.astype(int)\n",
    "        X_train = X_train*255\n",
    "        X_train = X_train.astype(int)\n",
    "        \n",
    "        combined = np.array([gen_imgs[0], gen_imgs[1], gen_imgs[2], gen_imgs[3], gen_imgs[4], gen_imgs[5], gen_imgs[6], gen_imgs[7], gen_imgs[8], gen_imgs[9]])\n",
    "        combined = np.hstack(combined.reshape(10, 384,384, 3))\n",
    "        imsave(savepath+\"images/\"+str(epoch)+\".png\", combined)\n",
    "        \n",
    "        combined = np.array([y_train[0], y_train[1], y_train[2], y_train[3], y_train[4], y_train[5], y_train[6], y_train[7], y_train[8], y_train[9]])\n",
    "        combined = np.hstack(combined.reshape(10, 384,384, 3))\n",
    "        imsave(savepath+\"images/\"+str(epoch)+\"_real.png\", combined)\n",
    "        \n",
    "        combined = np.array([X_train[0], X_train[1], X_train[2], X_train[3], X_train[4], X_train[5], X_train[6], X_train[7], X_train[8], X_train[9]])\n",
    "        combined = np.hstack(combined.reshape(10, 384,384, 3))\n",
    "        imsave(savepath+\"images/\"+str(epoch)+\"_lowres.png\", combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:109: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ba..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 640, 480, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 640, 480, 8)  224         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 640, 480, 8)  0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 640, 480, 8)  584         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 640, 480, 8)  0           batch_normalization_83[0][0]     \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 640, 480, 8)  584         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 640, 480, 8)  0           batch_normalization_85[0][0]     \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 640, 480, 8)  584         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 640, 480, 8)  0           batch_normalization_88[0][0]     \n",
      "                                                                 batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 640, 480, 8)  584         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, 640, 480, 8)  0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 640, 480, 8)  32          leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 640, 480, 8)  584         batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 640, 480, 8)  2457600     conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 640, 480, 8)  32          p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 640, 480, 3)  219         batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, 640, 480, 3)  0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 640, 480, 3)  12          leaky_re_lu_84[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,464,863\n",
      "Trainable params: 2,464,665\n",
      "Non-trainable params: 198\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  G loss  2.2478147\n",
      "Epoch  1  G loss  2.3788047\n",
      "Epoch  2  G loss  1.7379737\n",
      "Epoch  3  G loss  2.1157131\n",
      "Epoch  4  G loss  1.837394\n",
      "Epoch  5  G loss  1.5790558\n",
      "Epoch  6  G loss  1.870225\n",
      "Epoch  7  G loss  1.4191728\n",
      "Epoch  8  G loss  1.8853705\n",
      "Epoch  9  G loss  1.3648465\n",
      "Epoch  10  G loss  1.9276135\n",
      "Epoch  11  G loss  1.2842991\n",
      "Epoch  12  G loss  1.5337355\n",
      "Epoch  13  G loss  1.5118074\n",
      "Epoch  14  G loss  1.3931231\n",
      "Epoch  15  G loss  1.7390432\n",
      "Epoch  16  G loss  1.4629221\n",
      "Epoch  17  G loss  1.3320756\n",
      "Epoch  18  G loss  1.3877605\n",
      "Epoch  19  G loss  1.1749347\n",
      "Epoch  20  G loss  1.4510566\n",
      "Epoch  21  G loss  1.3590536\n",
      "Epoch  22  G loss  1.3707373\n",
      "Epoch  23  G loss  1.7077756\n",
      "Epoch  24  G loss  1.2668923\n"
     ]
    }
   ],
   "source": [
    "cgan = CGAN()\n",
    "cgan.build_autoencoder()\n",
    "cgan.train_generator_autoencoder(25, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.823161840438843\n",
      "0.9678699970245361\n",
      "0.9798541069030762\n",
      "0.9841511249542236\n",
      "0.9934227466583252\n",
      "0.971282958984375\n",
      "0.9897301197052002\n",
      "0.9745113849639893\n",
      "0.9787354469299316\n",
      "1.0341806411743164\n",
      "0.9499044418334961\n",
      "0.9322893619537354\n",
      "0.9754765033721924\n",
      "0.9426059722900391\n",
      "0.9431202411651611\n",
      "0.9533538818359375\n",
      "0.9376301765441895\n",
      "0.953239917755127\n",
      "0.9701035022735596\n",
      "0.9451735019683838\n",
      "0.9389424324035645\n",
      "0.947298526763916\n",
      "0.9366376399993896\n",
      "0.9384880065917969\n",
      "0.9442243576049805\n",
      "0.9448287487030029\n",
      "0.9380161762237549\n",
      "0.9380192756652832\n",
      "0.9408519268035889\n",
      "0.9456193447113037\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(30):\n",
    "    x = myGenerator(30)\n",
    "    xtest, ytest = next(x)\n",
    "    a = time.time()\n",
    "    pred = cgan.generator.predict(xtest)\n",
    "    b = time.time()\n",
    "    print(b-a)\n",
    "    pred = pred*255\n",
    "    pred = pred.astype(int)\n",
    "    #plt.imshow(pred[0])\n",
    "    #plt.show()\n",
    "    ytest = ytest*127.5+127.5\n",
    "    ytest = ytest.astype(int)\n",
    "    #plt.imshow(ytest[0])\n",
    "    #plt.show()\n",
    "    #imsave(path+'test/frame_pred'+str(i)+'.png', pred[0])\n",
    "    #imsave(path+'test/frame_real'+str(i)+'.png', ytest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import math\n",
    "import cv2\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(100):\n",
    "    img1 = cv2.imread(path+'test/frame_real'+str(i)+'.png')\n",
    "    img2 = cv2.imread(path+'test/frame_pred'+str(i)+'.png')\n",
    "    d = psnr(img1, img2)\n",
    "    data.append(d)\n",
    "    print(d)\n",
    "print('PSNR:', np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
